<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>rocnet.model &#8212; rocnet-example  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=27fed22d" />
    <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for rocnet.model</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Recursive NN for compressing voxel grids&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">log2</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>

<span class="kn">from</span> <span class="nn">rocnet.octree</span> <span class="kn">import</span> <span class="n">Octree</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
<span class="n">log_handler_stdout</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">StreamHandler</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">log_handler_stdout</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_leaf_layer_sizes</span><span class="p">(</span><span class="n">leaf_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">is_encoder</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the kernel size, stride, and padding for the three convolutional layers of the leaf encoder or decoder</span>
<span class="sd">    leaf_dim should be one of 8, 16, 32</span>
<span class="sd">    is_encoder specifies whether this is the encoding or decoding layer (the sizes are reversed for the latter)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lut</span> <span class="o">=</span> <span class="p">{</span>
        <span class="mi">32</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;kernel_sizes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="s2">&quot;conv_stride&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s2">&quot;conv_padding&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]},</span>
        <span class="mi">16</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;kernel_sizes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="s2">&quot;conv_stride&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s2">&quot;conv_padding&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]},</span>
        <span class="mi">8</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;kernel_sizes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;conv_stride&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;conv_padding&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]},</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="n">leaf_dim</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">lut</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;leaf_d=</span><span class="si">{</span><span class="n">leaf_dim</span><span class="si">}</span><span class="s2"> (allowed values are 8, 16, or 32)&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_encoder</span><span class="p">:</span>
        <span class="n">lut</span><span class="p">[</span><span class="n">leaf_dim</span><span class="p">][</span><span class="s2">&quot;kernel_sizes&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
        <span class="n">lut</span><span class="p">[</span><span class="n">leaf_dim</span><span class="p">][</span><span class="s2">&quot;conv_stride&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
        <span class="n">lut</span><span class="p">[</span><span class="n">leaf_dim</span><span class="p">][</span><span class="s2">&quot;conv_padding&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">lut</span><span class="p">[</span><span class="n">leaf_dim</span><span class="p">][</span><span class="s2">&quot;kernel_sizes&quot;</span><span class="p">],</span> <span class="n">lut</span><span class="p">[</span><span class="n">leaf_dim</span><span class="p">][</span><span class="s2">&quot;conv_stride&quot;</span><span class="p">],</span> <span class="n">lut</span><span class="p">[</span><span class="n">leaf_dim</span><span class="p">][</span><span class="s2">&quot;conv_padding&quot;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_check_params</span><span class="p">(</span><span class="n">grid_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">leaf_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">feature_code_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check whether grid_dim, leaf_dim, and feature_code_size are valid values&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">grid_dim</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">leaf_dim</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">feature_code_size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">feature_code_size</span> <span class="o">&lt;=</span> <span class="mi">8192</span>


<span class="k">class</span> <span class="nc">_RootEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Encode the Octree root node&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_code_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">node_channels</span><span class="p">,</span> <span class="n">feature_code_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">):</span>
                <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">class</span> <span class="nc">_LeafEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This encodes non-empty leaf nodes&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">leaf_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">voxel_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_layer_ks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layer_ss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layer_ps</span> <span class="o">=</span> <span class="n">_leaf_layer_sizes</span><span class="p">(</span><span class="n">leaf_dim</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">voxel_channels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ks</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ss</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ps</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ks</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ss</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ps</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ks</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ss</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ps</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="n">node_channels</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">):</span>
                <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">leaf_input</span><span class="p">):</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">leaf_input</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>

        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>

        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">leaf_vector</span>


<span class="k">class</span> <span class="nc">_LeafEncoderEmpty</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This encodes empty leaf nodes&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_channels</span> <span class="o">=</span> <span class="n">node_channels</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">leaf_feature</span><span class="p">):</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">leaf_feature</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">leaf_vector</span>


<span class="k">class</span> <span class="nc">_NodeEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Encode internal nodes&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">node_channels_inernal</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">child_conv</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">node_channels</span><span class="p">,</span> <span class="n">node_channels_inernal</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)]</span>
        <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;child</span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mod</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">child_conv</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">child_bn</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="n">node_channels_inernal</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)]</span>
        <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mod</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">child_bn</span><span class="p">)]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bn11</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="n">node_channels_inernal</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">second</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">node_channels_inernal</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn12</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="n">node_channels</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">):</span>
                <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">child_features</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">bn</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">ii</span><span class="p">))</span> <span class="k">for</span> <span class="p">(</span><span class="n">bn</span><span class="p">,</span> <span class="n">conv</span><span class="p">,</span> <span class="n">ii</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">child_bn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">child_conv</span><span class="p">,</span> <span class="n">child_features</span><span class="p">)])</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn11</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">second</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn12</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>


<div class="viewcode-block" id="Encoder">
<a class="viewcode-back" href="../../rocnet.html#rocnet.model.Encoder">[docs]</a>
<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Module to encode all the nodes in the  tree&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">_check_params</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">grid_dim</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">leaf_dim</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">feature_code_size</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leaf_encoder</span> <span class="o">=</span> <span class="n">_LeafEncoder</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">leaf_dim</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">voxel_channels</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">node_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leaf_encoder_empty</span> <span class="o">=</span> <span class="n">_LeafEncoderEmpty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">node_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">log2</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">grid_dim</span> <span class="o">/</span> <span class="n">cfg</span><span class="o">.</span><span class="n">leaf_dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_encoders</span> <span class="o">=</span> <span class="p">[</span><span class="n">_NodeEncoder</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">node_channels</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">node_channels_internal</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span><span class="p">)]</span>
        <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NodeEncoder</span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mod</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_encoders</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">has_root_encoder</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">root_encoder</span> <span class="o">=</span> <span class="n">_RootEncoder</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">feature_code_size</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">node_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">has_root_encoder</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">has_root_encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leaf_dim</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">leaf_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grid_dim</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">grid_dim</span>

    <span class="k">def</span> <span class="nf">_tf_encode_leaf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">leaf</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_encoder</span><span class="p">(</span><span class="n">leaf</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_encode_empty_leaf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">leaf</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_encoder_empty</span><span class="p">(</span><span class="n">leaf</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_encode_node_lvl0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_encoders</span><span class="p">[</span><span class="mi">0</span><span class="p">]([</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_tf_encode_node_lvl1</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_encoders</span><span class="p">[</span><span class="mi">1</span><span class="p">]([</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_tf_encode_node_lvl2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_encoders</span><span class="p">[</span><span class="mi">2</span><span class="p">]([</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_tf_encode_node_lvl4</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_encoders</span><span class="p">[</span><span class="mi">4</span><span class="p">]([</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_tf_encode_node_lvl5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_encoders</span><span class="p">[</span><span class="mi">5</span><span class="p">]([</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_tf_encode_root</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">root_encoder</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span>

<div class="viewcode-block" id="Encoder.forward">
<a class="viewcode-back" href="../../rocnet.html#rocnet.model.Encoder.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">leaf_features</span><span class="p">,</span> <span class="n">node_types</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert the provided points to an Octree, encode the octree and return the latent vector&quot;&quot;&quot;</span>
        <span class="n">tree</span> <span class="o">=</span> <span class="n">Octree</span><span class="p">(</span><span class="n">leaf_features</span><span class="p">,</span> <span class="n">node_types</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_tree</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span></div>


<div class="viewcode-block" id="Encoder.encode_tree">
<a class="viewcode-back" href="../../rocnet.html#rocnet.model.Encoder.encode_tree">[docs]</a>
    <span class="k">def</span> <span class="nf">encode_tree</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tree</span><span class="p">:</span> <span class="n">Octree</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">encode_node</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">level</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">is_leaf</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">is_empty_leaf</span><span class="p">():</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_encoder_empty</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">leaf_feature</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_encoder</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">leaf_feature</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">is_non_leaf</span><span class="p">():</span>
                <span class="n">children</span> <span class="o">=</span> <span class="p">[</span><span class="n">encode_node</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">level</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">children</span><span class="p">]</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_encoders</span><span class="p">[</span><span class="n">level</span><span class="p">](</span><span class="n">children</span><span class="p">)</span>

        <span class="n">encoding</span> <span class="o">=</span> <span class="n">encode_node</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_root_encoder</span><span class="p">:</span>
            <span class="n">root_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">root_encoder</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">root_code</span> <span class="o">=</span> <span class="n">encoding</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">root_code</span></div>
</div>



<span class="k">class</span> <span class="nc">_RootDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Decode a randomly sampled noise into a feature vector&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_code_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">deconv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">(</span><span class="n">feature_code_size</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">):</span>
                <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_feature</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">input_feature</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_feature</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deconv1</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">class</span> <span class="nc">_NodeClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_code_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">classifier_hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">node_channels</span><span class="p">,</span> <span class="n">feature_code_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">feature_code_size</span><span class="p">,</span> <span class="n">classifier_hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">classifier_hidden_size</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">):</span>
                <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_feature</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">input_feature</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp1</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp2</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">class</span> <span class="nc">_NodeDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Decode an input (parent) feature into a left-child and a right-child feature&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">node_channels_internal</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">(</span><span class="n">node_channels</span><span class="p">,</span> <span class="n">node_channels_internal</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">child_mlp</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">(</span><span class="n">node_channels_internal</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)]</span>
        <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mlp_child</span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mod</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">child_mlp</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">child_bn</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="n">node_channels</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)]</span>
        <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mod</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">child_bn</span><span class="p">)]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="n">node_channels_internal</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">):</span>
                <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parent_feature</span><span class="p">):</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">parent_feature</span><span class="p">)))</span>

        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">bn</span><span class="p">(</span><span class="n">mlp</span><span class="p">(</span><span class="n">vector</span><span class="p">)))</span> <span class="k">for</span> <span class="p">(</span><span class="n">bn</span><span class="p">,</span> <span class="n">mlp</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">child_bn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">child_mlp</span><span class="p">)]</span>


<span class="k">class</span> <span class="nc">_LeafDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">leaf_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">voxel_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">node_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_layer_ks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layer_ss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layer_ps</span> <span class="o">=</span> <span class="n">_leaf_layer_sizes</span><span class="p">(</span><span class="n">leaf_dim</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">deconv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">(</span><span class="n">node_channels</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ks</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ss</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ps</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deconv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ks</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ss</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ps</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deconv4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">voxel_channels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ks</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ss</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_layer_ps</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">):</span>
                <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">leaf_input</span><span class="p">):</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deconv2</span><span class="p">(</span><span class="n">leaf_input</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>

        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deconv3</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>

        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deconv4</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">)</span>
        <span class="n">leaf_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">leaf_vector</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">1e-7</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">leaf_vector</span>


<div class="viewcode-block" id="Decoder">
<a class="viewcode-back" href="../../rocnet.html#rocnet.model.Decoder">[docs]</a>
<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Module to decode all the nodes in the  tree&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Init RocNet octree decoder</span>

<span class="sd">        leaf_dim: Edge length of the cube of voxels which makes up a leaf node</span>
<span class="sd">        grid_dim: Edge length of the voxel grid which RocNet operates on</span>
<span class="sd">        voxel_channels: Number of data channels plus one. i.e. Occupancy-only is 0+1=1, R-G-B colour is 3+1=4</span>
<span class="sd">        feature_code_size: Size of the final output vector</span>
<span class="sd">        classifier_hidden_size: ???</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_params</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">grid_dim</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">leaf_dim</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">feature_code_size</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leaf_decoder</span> <span class="o">=</span> <span class="n">_LeafDecoder</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">leaf_dim</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">voxel_channels</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">node_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">log2</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">grid_dim</span> <span class="o">/</span> <span class="n">cfg</span><span class="o">.</span><span class="n">leaf_dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_decoders</span> <span class="o">=</span> <span class="p">[</span><span class="n">_NodeDecoder</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">node_channels</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">node_channels_internal</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span><span class="p">)]</span>
        <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NodeDecoder</span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mod</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_decoders</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">has_root_encoder</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">root_decoder</span> <span class="o">=</span> <span class="n">_RootDecoder</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">feature_code_size</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">node_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">has_root_decoder</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">has_root_encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_classifier</span> <span class="o">=</span> <span class="n">_NodeClassifier</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">feature_code_size</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">classifier_hidden_size</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">node_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leaf_dim</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">leaf_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grid_dim</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">grid_dim</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">classify_creloss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">recon_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recon_loss_occupancy</span> <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">voxel_channels</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recon_loss_color</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_scale</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">loss_params</span><span class="o">.</span><span class="n">label_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">recon_scale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">leaf_dim</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cre_occupied_factor</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">loss_params</span><span class="o">.</span><span class="n">recon_cre_gamma</span> <span class="o">*</span> <span class="n">cfg</span><span class="o">.</span><span class="n">loss_params</span><span class="o">.</span><span class="n">recon_cre_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cre_empty_factor</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cfg</span><span class="o">.</span><span class="n">loss_params</span><span class="o">.</span><span class="n">recon_cre_gamma</span><span class="p">)</span> <span class="o">*</span> <span class="n">cfg</span><span class="o">.</span><span class="n">loss_params</span><span class="o">.</span><span class="n">recon_cre_scale</span>

<div class="viewcode-block" id="Decoder.forward">
<a class="viewcode-back" href="../../rocnet.html#rocnet.model.Decoder.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_vector</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Decode the latent vector and return an array of points&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode_tree</span><span class="p">(</span><span class="n">latent_vector</span><span class="p">)</span></div>


<div class="viewcode-block" id="Decoder.decode_tree">
<a class="viewcode-back" href="../../rocnet.html#rocnet.model.Decoder.decode_tree">[docs]</a>
    <span class="k">def</span> <span class="nf">decode_tree</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_vector</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_root_decoder</span><span class="p">:</span>
            <span class="n">decode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">root_decoder</span><span class="p">(</span><span class="n">latent_vector</span><span class="p">)</span>
            <span class="n">stack</span> <span class="o">=</span> <span class="p">[</span><span class="n">decode</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stack</span> <span class="o">=</span> <span class="p">[</span><span class="n">latent_vector</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">node_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span>
        <span class="n">leaf_features</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">node_types</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">depth</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">stack</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">f</span> <span class="o">=</span> <span class="n">stack</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">depth</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
            <span class="n">label_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_classifier</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">label_prob</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="n">d</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_decoders</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Leaf classifier returned internal node at max tree depth; decoding a full leaf instead&quot;</span><span class="p">)</span>
                <span class="n">leaf_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">voxel_channels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_dim</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
                <span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">elif</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># NON-LEAF</span>
                <span class="n">children</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_decoders</span><span class="p">[</span><span class="n">d</span> <span class="o">-</span> <span class="mi">1</span><span class="p">](</span><span class="n">f</span><span class="p">)</span>
                <span class="n">children</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
                <span class="n">stack</span> <span class="o">=</span> <span class="n">stack</span> <span class="o">+</span> <span class="n">children</span>
                <span class="n">depth</span> <span class="o">=</span> <span class="n">depth</span> <span class="o">+</span> <span class="p">[</span><span class="n">d</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)]</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># LEAF</span>
                <span class="n">reBox</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_decoder</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                <span class="n">leaf_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reBox</span><span class="p">)</span>

            <span class="n">node_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        <span class="n">node_types_sorted_tensor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">node_types</span><span class="p">)))</span>
        <span class="n">features_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">leaf_features</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">features_tensor</span><span class="p">,</span> <span class="n">node_types_sorted_tensor</span></div>


    <span class="k">def</span> <span class="nf">_recon_loss_occupancy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">leaf_est</span><span class="p">,</span> <span class="n">leaf_gt</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Binary cross-entropy loss similar to that formulated by Brock2016</span>

<span class="sd">        self.cre_gamma corresponds to the gamma factor in Brock2016, however target/observed values remain on the [0..1] range.</span>
<span class="sd">        self.cre_scale normalizes the loss  value to the number of voxels in a leaf block.</span>

<span class="sd">        The Liu2020 implementation originally scaled the &#39;occupied&#39; half by 5 and then scaled the total score by 0.001.</span>
<span class="sd">        For the same relative occupied/unoccupied weighting use cre_gamma=0.83 and recon_scale=6</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">occ_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">gt</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cre_occupied_factor</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">est</span><span class="p">)))</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">gt</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cre_empty_factor</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">est</span><span class="p">)))))</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recon_scale</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">est</span><span class="p">,</span> <span class="n">gt</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">leaf_est</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="n">leaf_gt</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">])],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">occ_loss</span>

    <span class="k">def</span> <span class="nf">_recon_loss_color</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">leaf_est</span><span class="p">,</span> <span class="n">leaf_gt</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Binary cross-entropy loss similar to that formulated by Brock2016</span>

<span class="sd">        self.cre_gamma corresponds to the gamma factor in Brock2016, however target/observed values remain on the [0..1] range.</span>
<span class="sd">        self.cre_scale normalizes the loss  value to the number of voxels in a leaf block.</span>

<span class="sd">        The Liu2020 implementation originally scaled the &#39;occupied&#39; half by 5 and then scaled the total score by 0.001.</span>
<span class="sd">        For the same relative occupied/unoccupied weighting use cre_gamma=0.83 and recon_scale=6</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">leaf_gt</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">attr_loss</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">leaf_gt</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:,</span> <span class="n">m</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">m</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">m</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]]</span> <span class="o">-</span> <span class="n">leaf_est</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:,</span> <span class="n">m</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">m</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">m</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]])))</span> <span class="o">/</span> <span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">occ_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">gt</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cre_occupied_factor</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">est</span><span class="p">)))</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">gt</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cre_empty_factor</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">est</span><span class="p">)))))</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recon_scale</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">est</span><span class="p">,</span> <span class="n">gt</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">leaf_est</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="n">leaf_gt</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">])],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">occ_loss</span> <span class="o">+</span> <span class="n">attr_loss</span>

    <span class="k">def</span> <span class="nf">_classify_loss_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">class_est</span><span class="p">,</span> <span class="n">class_gt</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">classify_creloss</span><span class="p">(</span><span class="n">l_est</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">l_gt</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_scale</span><span class="p">)</span> <span class="k">for</span> <span class="n">l_est</span><span class="p">,</span> <span class="n">l_gt</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">class_est</span><span class="p">,</span> <span class="n">class_gt</span><span class="p">)],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

<div class="viewcode-block" id="Decoder.decode_loss">
<a class="viewcode-back" href="../../rocnet.html#rocnet.model.Decoder.decode_loss">[docs]</a>
    <span class="k">def</span> <span class="nf">decode_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_code</span><span class="p">,</span> <span class="n">expected_tree</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Decodes the feature to an octree and computes the loss function.</span>

<span class="sd">        Recursively accumulates the classifier and reconstruction losses for the whole tree.</span>

<span class="sd">        model: rocnet model to use for decoding</span>
<span class="sd">        feature: feature vector to decode</span>
<span class="sd">        tree: expected octree structure</span>
<span class="sd">        returns: [reconstruction_loss, node_classifier_loss] (a tensor with two elements)&quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">decode_node_leaf</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">est</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
            <span class="n">label_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_classifier</span><span class="p">(</span><span class="n">est</span><span class="p">)</span>
            <span class="n">label_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_classify_loss_fn</span><span class="p">(</span><span class="n">label_prob</span><span class="p">,</span> <span class="n">tgt</span><span class="o">.</span><span class="n">node_type</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">tgt</span><span class="o">.</span><span class="n">is_leaf</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">tgt</span><span class="o">.</span><span class="n">is_empty_leaf</span><span class="p">():</span>
                    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">label_loss</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">fea</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_decoder</span><span class="p">(</span><span class="n">est</span><span class="p">)</span>
                    <span class="n">recon_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recon_loss</span><span class="p">(</span><span class="n">fea</span><span class="p">,</span> <span class="n">tgt</span><span class="o">.</span><span class="n">leaf_feature</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
                    <span class="k">return</span> <span class="n">recon_loss</span><span class="p">,</span> <span class="n">label_loss</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># Non-leaf node</span>
                <span class="n">children</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_decoders</span><span class="p">[</span><span class="n">l</span><span class="p">](</span><span class="n">est</span><span class="p">)</span>
                <span class="n">child_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">decode_node_leaf</span><span class="p">(</span><span class="n">tgt_child</span><span class="p">,</span> <span class="n">est_child</span><span class="p">,</span> <span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">tgt_child</span><span class="p">,</span> <span class="n">est_child</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tgt</span><span class="o">.</span><span class="n">children</span><span class="p">,</span> <span class="n">children</span><span class="p">)]</span>

                <span class="n">child_recon_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">loss</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">child_losses</span><span class="p">])</span>
                <span class="n">child_label_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">loss</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">child_losses</span><span class="p">])</span>

                <span class="k">return</span> <span class="n">child_recon_loss</span><span class="p">,</span> <span class="n">child_label_loss</span> <span class="o">+</span> <span class="n">label_loss</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_root_decoder</span><span class="p">:</span>
            <span class="n">feature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">root_decoder</span><span class="p">(</span><span class="n">feature_code</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">feature</span> <span class="o">=</span> <span class="n">feature_code</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">node_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">recon_loss</span><span class="p">,</span> <span class="n">label_loss</span> <span class="o">=</span> <span class="n">decode_node_leaf</span><span class="p">(</span><span class="n">expected_tree</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">recon_loss</span><span class="p">,</span> <span class="n">label_loss</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">_tf_decode_leaf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_decoder</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_decode_empty_leaf</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_decode_node_lvl0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_decoders</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">feature</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_decode_node_lvl1</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_decoders</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">feature</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_decode_node_lvl2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_decoders</span><span class="p">[</span><span class="mi">2</span><span class="p">](</span><span class="n">feature</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_decode_node_lvl3</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_decoders</span><span class="p">[</span><span class="mi">3</span><span class="p">](</span><span class="n">feature</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_decode_node_lvl4</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_decoders</span><span class="p">[</span><span class="mi">4</span><span class="p">](</span><span class="n">feature</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_decode_node_lvl5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_decoders</span><span class="p">[</span><span class="mi">5</span><span class="p">](</span><span class="n">feature</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_decode_root</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">code</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">root_decoder</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_classify_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_classifier</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tf_vec_sum_2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_tf_vec_sum_8</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Boilerplate to make things work with torchfold&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="n">c5</span><span class="p">,</span> <span class="n">c6</span><span class="p">,</span> <span class="n">c7</span><span class="p">,</span> <span class="n">c8</span><span class="p">])</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">rocnet-example</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../examine_dataset.html">examine_dataset module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examine_training_run.html">examine_training_run module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../test_file.html">test_file module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../test_tile.html">test_tile module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tile.html">tile module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../train.html">train module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../utils.html">utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rocnet.html">rocnet package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, Author.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
  </body>
</html>